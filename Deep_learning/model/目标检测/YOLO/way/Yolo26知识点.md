[源文档](https://docs.ultralytics.com/zh/models/yolo26/)
Yolo26 专为**边缘和低功耗设备**而设计
![[Yolo26.png]]
# 1. 概述
YOLO26 的架构遵循三个核心原则：
- **简洁性：** YOLO26 是一个**原生端到端模型**，直接生成预测，而**无需非极大值抑制 (NMS)**。通过消除此后处理步骤，推理变得更快、更轻，并且更易于在实际系统中部署。清华大学的 Ao Wang 在 `YOLOv10` 中首次开创了这种突破性方法，并在 YOLO26 中得到了进一步发展。
- **部署效率：** 端到端设计消除了管道的整个阶段，从而大大简化了集成，减少了延迟，并使部署在各种环境中更加稳健。
- **训练创新：** YOLO26 引入了 **MuSGD 优化器**，它是 SGD 和 Muon 的混合体 — 受 Moonshot AI 的 Kimi K2 在 LLM 训练方面的突破启发。该优化器带来了增强的稳定性和更快的收敛速度，从而将语言模型的优化进展转移到计算机视觉中。
这些创新共同提供了一个模型系列，该模型系列在小对象上实现了更高的精度，提供了无缝部署，并且在 **CPU 上的运行速度提高了 43%** — 使 YOLO26 成为迄今为止资源受限环境中最实用和可部署的 YOLO 模型之一。
# 2. 相对前系列的主要改进
## 2.1DFL 移除
分布焦点损失 (DFL) 模块虽然有效，但通常会使导出复杂化并限制硬件兼容性。YOLO26 完全移除了 DFL，从而简化了推理并扩大了对**边缘和低功耗设备**的支持。
- [DFL模块详情](分布焦点损失DFL模块)
DFL最初的设计目的是通过预测框坐标的概率分布来改进包围盒回归，从而实现更精确的物体定位。  
在实际应用中，DFL需要在推理和模型导出过程中进行专门处理，这使得针对ONNX、CoreML、TensorRT或TFLite等硬件加速器的部署管线变得复杂。
![[Yolo26_1.png]]
**通过消除DFL，YOLO26简化了模型的架构，使得边界框预测在不牺牲性能的情况下成为一个更直接的回归任务**
## 2.2  **端到端 NMS-Free 推理**  
与依赖 NMS 作为单独后处理步骤的传统检测器不同，YOLO26 是**原生端到端**的。直接生成预测，从而减少了延迟，并使集成到生产系统中的速度更快、更轻且更可靠。
### 2.2.1 修改出发点
之前的YOLO包括YOLOv8到YOLOv13，严重依赖NMS作为后处理步骤，通过仅保留置信度得分最高的边界框来过滤重复的预测。**NMS虽然有效，但会给管道增加额外的延迟，并且需要手动调整超参数**，如交并比( Intersection-over-Union，IoU )阈值。这种对手工后处理步骤的依赖在部署管道中引入了脆弱性，特别是对于边缘设备和延迟敏感的应用程序。
- 换言之，这个模块会给部署增加额外负担
![[Yolo26_2.png]]
### 2.2.2 修改方法
1. YOLO26从根本上重新设计了预测头，在不需要NMS的情况下产生直接的、非冗余的包围盒预测。这种端到端的设计不仅降低了推理复杂度，而且消除了对手动调节阈值的依赖，从而简化了与生产系统的集成
2. **NMS - free方法提高了可重复性和部署可移植性，因为模型不再需要大量的后处理代码**。虽然其他先进的检测器如RT - DETR和Sparse R - CNN已经尝试了NMS - free推理，但YOLO26代表了第一个采用该范式的YOLO版本，同时保持了YOLO在速度和准确性之间的平衡。相比于依旧依赖于NMS的YOLOv13，YOLO26的端到端流水线作为实时检测的前瞻性架构脱颖而出。
## 2.3 **ProgLoss + STAL**  
改进的损失函数提高了检测精度，尤其是在**小对象识别**方面，这是物联网、机器人技术、航空图像和其他边缘应用的关键要求。
### 2.3.1 出发点
训练稳定性和小目标识别仍然是目标检测中持续存在的挑战
- 早期的模型如YOLOv8和YOLOv11并没有融入这样的针对性机制，往往需要数据集特定的扩增或外部训练技巧来达到可接受的小目标性能。YOLOv12和YOLOv13试图通过基于注意力的模块和增强的多尺度特征融合来解决这一差距；然而，这些解决方案增加了架构复杂性和推理成本
YOLO26通过整合两种新颖的策略来解决这些问题：渐进损失平衡( ProgLoss )和小目标感知标签分配( STAL )
![[Yolo26_3.png]]
### 2.3.2 ProgLoss
ProgLoss在训练过程中动态调整不同损失成分的权重，保证模型在稀有类或小类上表现不佳的同时不过度拟合主导对象类别。这种渐进式的再平衡提高了泛化能力，并防止了训练后期的不稳定性
### 2.3.3 STAL
STAL明确地对小物体进行优先的标签分配，这些小物体由于其有限的像素表示和易受遮挡的影响而特别难以检测
## 2.4  **MuSGD 优化器**  
一种新的混合优化器，它将 SGD 与 Muon 相结合。受 Moonshot AI 的 Kimi K2 的启发，MuSGD 将 LLM 训练中的高级优化方法引入到计算机视觉中，从而实现更稳定的训练和更快的收敛。

该优化器结合了随机梯度下降( SGD )和最近提出的Muon优化器的优点，该优化器受用于大型语言模型( LLM )训练的优化策略的启发。Mu SGD利用了SGD的鲁棒性和泛化能力，同时结合了Muon的自适应特性，能够在不同的数据集上实现更快的收敛和更稳定的优化。
![[Yolo26_4.png]]
1. 这种混合优化器反映了现代深度学习的一个重要趋势：自然语言处理( NLP )和计算机视觉之间的交叉  
2. Mu SGD使YOLO26能够以更少的训练次数达到具有竞争力的精度，减少了训练时间和计算成本
# 3. Yolo改的思路
1. 通过建立基础模型和大规模预训练，下一代YOLO可以作为通用的视觉AI，无缝地处理上下文中新物体的检测、分割甚至描述
2. 在目标检测的半监督和自监督学习领域。目前最先进的检测器仍然严重依赖于大型有标记数据集，但研究正在快速推进在无标记或部分标记数据上进行训练的方法。师生训练、伪标注和自监督特征学习等技术可以集成到YOLO训练流水线中，以减少对大量人工标注的需求。未来的YOLO可能会自动利用大量未标注的图像或视频来提高识别的鲁棒性。 通过这样做，该模型可以在标记数据没有成比例增加的情况下继续提高其检测能力，使其更适应新的领域或稀有对象类别
3. "基于CNN的"和"基于transformer的"检测器之间的界限将继续模糊，充分利用这两个世界来处理多样化的检测挑战
4. 由于部署仍然是一个重要的问题，未来的研究可能会强调边缘感知的训练和优化。这意味着从训练阶段开始，模型开发将越来越多地考虑硬件约束，而不仅仅是事后的考虑